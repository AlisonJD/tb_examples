{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Add_a_Column_to_a_Data_Source_using_the_CLI.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yunNOBebQ1qD",
        "qlxWb-MjS64g",
        "dBPMjutHYt0r",
        "6nbESu4OngbS",
        "4XPdsAMfntOc"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNR04SLREWsrm9x0x8mj41+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlisonJD/tb_examples/blob/main/Add_a_Column_to_a_Data_Source_using_the_CLI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yunNOBebQ1qD"
      },
      "source": [
        "# Add a Column to a Data Source using the CLI\n",
        "\n",
        "Based on Tinybird blog post:\n",
        "\n",
        "https://blog.tinybird.co/2021/05/25/add-column/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m9SGvMoQ2M7",
        "outputId": "12cb740c-dc5b-444f-b424-043a989d23ad"
      },
      "source": [
        "#@title Mount your Google Drive to save and use local files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)\n",
        "\n",
        "% cd \"/content/gdrive/My Drive/Colab Notebooks/Tinybird/tb_examples\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks/Tinybird/tb_examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dDX75NlROEj"
      },
      "source": [
        "#@title Install Tinybird CLI, os and your token\n",
        "!pip install tinybird-cli -q\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.isfile('.tinyb'):\n",
        "  !tb auth\n",
        "\n",
        "if not os.path.isdir('datasources'):\n",
        "  !tb init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok4fXnpES1Vd"
      },
      "source": [
        "#@title Helper function to write to files\n",
        "def write_text_to_file(filename, text):\n",
        "  with open(filename, 'w') as f: f.write(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQjLeU4mRkNR"
      },
      "source": [
        "# Worked Example from Blog:\n",
        "\n",
        "# Add a Column to a Data Source using the CLI\n",
        "\n",
        "Business changes, so does data. New attributes in datasets are the norm, not the exception.\n",
        "\n",
        "You can now add new columns to your existing Data Sources, without worrying about what happens with your existing data ingestion (we will keep importing data with the old schema and start accepting data with the new schema).\n",
        "\n",
        "Since you can materialize data to other Data Sources at ingestion time, changing the schema of your Data Source could have downstream effects. Don't worry we've solved that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlxWb-MjS64g"
      },
      "source": [
        "## Create a Sample Data Source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUn4TURuTQbe"
      },
      "source": [
        "filename=\"datasources/fixtures/my_ds.csv\"\n",
        "text='''\n",
        "n,v\n",
        "1,A\n",
        "2,B\n",
        "3,C\n",
        "4,D\n",
        "5,E\n",
        "6,F\n",
        "7,G\n",
        "\n",
        "'''\n",
        "\n",
        "write_text_to_file(filename, text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0L9ZWHETqfg",
        "outputId": "acfa57a9-3717-4c2f-8acd-37abc62da513"
      },
      "source": [
        "!tb datasource generate datasources/fixtures/my_ds.csv --force"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m** Generated datasources/my_ds.datasource\n",
            "** => Create it on the server running: $ tb push datasources/my_ds.datasource\n",
            "** => Append data using: $ tb datasource append my_ds datasources/fixtures/my_ds.csv`\n",
            "\u001b[0m\n",
            "\u001b[92m** => Generated fixture datasources/fixtures/my_ds.csv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKPAkFWiVuul",
        "outputId": "a46e2fd0-41b1-492a-f55b-2b7aa61cc86e"
      },
      "source": [
        "!cat datasources/my_ds.datasource"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DESCRIPTION generated from datasources/fixtures/my_ds.csv\n",
            "\n",
            "SCHEMA >\n",
            "    `n` Int16,\n",
            "    `v` String"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GzyCEBRT2J_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f51fe1-7dcb-411b-8aad-4ca50771bb47"
      },
      "source": [
        "!tb datasource append my_ds datasources/fixtures/my_ds.csv\n",
        "# the row in quaratine is the row containing column names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m** ü•ö starting import process\u001b[0m\n",
            "\u001b[91m\n",
            "** There was an error with file contents: 1 row in quarantine.\u001b[0m\n",
            "\u001b[92m** üê• done\u001b[0m\n",
            "\u001b[92m** Appended 8 new rows\u001b[0m\n",
            "\u001b[92m** Total rows in my_ds: 7\u001b[0m\n",
            "\u001b[92m** Data appended to Data Source 'my_ds' successfully!\u001b[0m\n",
            "\u001b[0m** Data pushed to my_ds\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOFjlAjOYj_C",
        "outputId": "49434072-7a1f-45ab-829d-439ac129d257"
      },
      "source": [
        "!tb sql \"select * from my_ds order by n\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------\n",
            "| \u001b[1;32mn\u001b[0m | \u001b[1;32mv\u001b[0m |\n",
            "---------\n",
            "| 1 | A |\n",
            "| 2 | B |\n",
            "| 3 | C |\n",
            "| 4 | D |\n",
            "| 5 | E |\n",
            "| 6 | F |\n",
            "| 7 | G |\n",
            "---------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBPMjutHYt0r"
      },
      "source": [
        "## Add New Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GYCjjXWYIqh"
      },
      "source": [
        "\n",
        "\n",
        "To add new columns, just add them to the end of the current schema definition and then do `tb push --force`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaJ13CSlYJdN"
      },
      "source": [
        "filename=\"datasources/my_ds.datasource\"\n",
        "text='''\n",
        "DESCRIPTION my_ds with some new columns\n",
        "\n",
        "SCHEMA >\n",
        "    `n` Int16,\n",
        "    `v` String,\n",
        "    `v_str_def_thing` String DEFAULT 'thing',\n",
        "    `v_str_no_default` String,\n",
        "    `v_int_def_3` Int16 DEFAULT 3,\n",
        "    `v_int_no_default` Int16\n",
        "\n",
        "'''\n",
        "\n",
        "write_text_to_file(filename, text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWzp86S1clVw",
        "outputId": "d65a39fa-1f07-41ad-d87b-4b5d6ce76662"
      },
      "source": [
        "!cat datasources/my_ds.datasource"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "DESCRIPTION my_ds with some new columns\n",
            "\n",
            "SCHEMA >\n",
            "    `n` Int16,\n",
            "    `v` String,\n",
            "    `v_str_def_thing` String DEFAULT 'thing',\n",
            "    `v_str_no_default` String,\n",
            "    `v_int_def_3` Int16 DEFAULT 3,\n",
            "    `v_int_no_default` Int16\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAx1jTkHY-e4",
        "outputId": "de1d6582-20fe-4db2-8efc-d5679f84636d"
      },
      "source": [
        "!tb push datasources/my_ds.datasource --force"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m** Processing datasources/my_ds.datasource\u001b[0m\n",
            "\u001b[0m** Building dependencies\u001b[0m\n",
            "\u001b[0m** Running my_ds \u001b[0m\n",
            "\u001b[0m** The schema of 'my_ds' has changed.\u001b[0m\n",
            "**   -  ADD COLUMN `v_str_def_thing` String DEFAULT 'thing'\n",
            "**   -  ADD COLUMN `v_str_no_default` String\n",
            "**   -  ADD COLUMN `v_int_def_3` Int16 DEFAULT 3\n",
            "**   -  ADD COLUMN `v_int_no_default` Int16\n",
            "\u001b[0m** Please confirm you want to apply the changes above y/N\u001b[0m: y\n",
            "\u001b[92m** The Data Source has been correctly updated.\u001b[0m\n",
            "\u001b[0m** Not pushing fixtures\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nbESu4OngbS"
      },
      "source": [
        "## Add Data with the New Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQyl4bSkZFnw"
      },
      "source": [
        "filename=\"datasources/fixtures/my_ds_new_cols.csv\"\n",
        "text='''\n",
        "n,v,v_str_def_thing,v_str_no_default,v_int_def_3,v_int_no_default\n",
        "8,H,other,word,5,10\n",
        "9,I,,dog,0,6\n",
        "10,J,again,words,1,8\n",
        "'''\n",
        "\n",
        "write_text_to_file(filename, text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhHKaMbfbx1p",
        "outputId": "486d3dad-3d9c-490d-e1a5-1e903d5c1347"
      },
      "source": [
        "!tb datasource append my_ds datasources/fixtures/my_ds_new_cols.csv\n",
        "# again the row of column names goes into quarantine"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m** ü•ö starting import process\u001b[0m\n",
            "\u001b[91m\n",
            "** There was an error with file contents: 1 row in quarantine.\u001b[0m\n",
            "\u001b[92m** üê• done\u001b[0m\n",
            "\u001b[92m** Appended 4 new rows\u001b[0m\n",
            "\u001b[92m** Total rows in my_ds: 10\u001b[0m\n",
            "\u001b[92m** Data appended to Data Source 'my_ds' successfully!\u001b[0m\n",
            "\u001b[0m** Data pushed to my_ds\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XPdsAMfntOc"
      },
      "source": [
        "## Add Data with the Old Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97XY3y1Ib5Th",
        "outputId": "d6b4e4b3-5e8f-41a3-e595-294e17c7ff9f"
      },
      "source": [
        "!tb sql \"select * from my_ds order by n\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "|  \u001b[1;32mn\u001b[0m | \u001b[1;32mv\u001b[0m | \u001b[1;32mv_str_def_thing\u001b[0m | \u001b[1;32mv_str_no_default\u001b[0m | \u001b[1;32mv_int_def_3\u001b[0m | \u001b[1;32mv_int_no_default\u001b[0m |\n",
            "--------------------------------------------------------------------------------\n",
            "|  1 | A | thing           |                  |           3 |                0 |\n",
            "|  2 | B | thing           |                  |           3 |                0 |\n",
            "|  3 | C | thing           |                  |           3 |                0 |\n",
            "|  4 | D | thing           |                  |           3 |                0 |\n",
            "|  5 | E | thing           |                  |           3 |                0 |\n",
            "|  6 | F | thing           |                  |           3 |                0 |\n",
            "|  7 | G | thing           |                  |           3 |                0 |\n",
            "|  8 | H | other           | word             |           5 |               10 |\n",
            "|  9 | I |                 | dog              |           0 |                6 |\n",
            "| 10 | J | again           | words            |           1 |                8 |\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBQWR7XnfjNd"
      },
      "source": [
        "By default columns will have an empty string or a 0, depending on the type. In the schema you can specify other default values for the new columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wkX5MX0maxe"
      },
      "source": [
        "filename=\"datasources/fixtures/my_ds_old_cols.csv\"\n",
        "text='''\n",
        "n,v\n",
        "11,K\n",
        "12,L\n",
        "\n",
        "'''\n",
        "\n",
        "write_text_to_file(filename, text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPoSBnGvmr5j",
        "outputId": "1e853020-8791-4457-eb72-4c16a5923286"
      },
      "source": [
        "!tb datasource append my_ds datasources/fixtures/my_ds_old_cols.csv\n",
        "# again the row of column names goes into quarantine"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m** ü•ö starting import process\u001b[0m\n",
            "\u001b[91m\n",
            "** There was an error with file contents: 1 row in quarantine.\u001b[0m\n",
            "\u001b[92m** üê• done\u001b[0m\n",
            "\u001b[92m** Appended 4 new rows\u001b[0m\n",
            "\u001b[92m** Total rows in my_ds: 12\u001b[0m\n",
            "\u001b[92m** Data appended to Data Source 'my_ds' successfully!\u001b[0m\n",
            "\u001b[0m** Data pushed to my_ds\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfSaEWg5myLr",
        "outputId": "f009aae4-cb67-4b95-8e38-96b94b139b03"
      },
      "source": [
        "!tb sql \"select * from my_ds order by n\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "|  \u001b[1;32mn\u001b[0m | \u001b[1;32mv\u001b[0m | \u001b[1;32mv_str_def_thing\u001b[0m | \u001b[1;32mv_str_no_default\u001b[0m | \u001b[1;32mv_int_def_3\u001b[0m | \u001b[1;32mv_int_no_default\u001b[0m |\n",
            "--------------------------------------------------------------------------------\n",
            "|  1 | A | thing           |                  |           3 |                0 |\n",
            "|  2 | B | thing           |                  |           3 |                0 |\n",
            "|  3 | C | thing           |                  |           3 |                0 |\n",
            "|  4 | D | thing           |                  |           3 |                0 |\n",
            "|  5 | E | thing           |                  |           3 |                0 |\n",
            "|  6 | F | thing           |                  |           3 |                0 |\n",
            "|  7 | G | thing           |                  |           3 |                0 |\n",
            "|  8 | H | other           | word             |           5 |               10 |\n",
            "|  9 | I |                 | dog              |           0 |                6 |\n",
            "| 10 | J | again           | words            |           1 |                8 |\n",
            "| 11 | K | thing           |                  |           3 |                0 |\n",
            "| 12 | L | thing           |                  |           3 |                0 |\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0uWBQ23k10q"
      },
      "source": [
        "## Notes\n",
        "1. If you are materializing views from the Data Source that you are adding columns to with `SELECT * FROM ...` the views will break because the target Data Sources won‚Äôt have all the columns. To avoid this, use column names instead of * when creating materialized views.\n",
        "\n",
        "2. You can only add columns to Data Sources that have a `Null` engine or one in the `MergeTree` family``\n",
        "\n",
        "3. You can keep importing data as if your schema hadn‚Äôt changed. Default values will be used for the new columns if a value is not provided for them. At any point, you can start importing with the new schema by sending data that contains the new columns.\n",
        "\n",
        "4. All the new columns have to be added at the end of the schema of a current Data Source not in between existing columns."
      ]
    }
  ]
}